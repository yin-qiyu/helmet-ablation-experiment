# æ¶ˆèå®éªŒ

æ•°æ®é›†ï¼š

1. [Safety Helmet Detection(kaggle.com)](https://www.kaggle.com/datasets/andrewmvd/hard-hat-detection)
2. [Hard Hat Workers Dataset (roboflow.com)](https://public.roboflow.com/object-detection/hard-hat-workers)



trainï¼š4500

valï¼š500

## åŸºç¡€å‚æ•°è®¾ç½®

```
default=8		 1 epochs completed in 0.017 hours.
default=32	 1 epochs completed in 0.013 hours.
default=64   1 epochs completed in 0.012 hours.
default=128  1 epochs completed in 0.014 hours.
```

batch-size: 32

Image-size: 640

```python
# Parameters
nc: 2  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.25  # layer channel multiple
```



## baseline

- exp25

- no-pretrain

  <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/image-20220408230521207.png" alt="image-20220408230521207" style="zoom:50%;" />



# é¢„è®­ç»ƒå’Œbatchæµ‹è¯•

- exp11

  cfg:yolov5n.yaml

  Model size:3.9M

  Pretrain: yolov5n

  batch-size: 32

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/image-20220407093516688.png" alt="image-20220407093516688" width="800" />

- exp15

  cfgï¼šyolov5n.yaml

  Model size:3.9M

  Pretrainï¼šnone
  batch-sizeï¼š128

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/image-20220407093558329.png" alt="image-20220407093558329" width="800"/>



##  batchæµ‹è¯•

- exp28
- yolov5n-Helmet.yaml
- batchï¼š128

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204092125408.png" alt="image-20220409212506365" width="800" />



# è½»é‡åŒ–ç½‘ç»œ

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204141946256.png" alt="è½»é‡åŒ–ç¥ç»ç½‘ç»œ" width="500" />



# è½»é‡åŒ–

## Shufflenetv2

> [Cite]Ma, Ningning, et al. â€œShufflenet v2: Practical guidelines for efficient cnn architecture design.â€ Proceedings of the European conference on computer vision (ECCV). 2018.
>
> [è®ºæ–‡åœ°å€](https://arxiv.org/abs/1807.11164)
>
> [è®ºæ–‡ä»£ç ](https://github.com/megvii-model/ShuffleNet-Series)

v1ä¸»è¦ç”¨çš„åˆ†ç»„å·ç§¯



### å®éªŒç»“æœ

- exp17

  cfg: yolov5-shufflenetv2.yaml

  Model size: 805kB

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/image-20220407093620656.png" alt="image-20220407093620656" width="800" />



## Mobilenetv3

> [Cite]Howard, Andrew, et al. â€œSearching for mobilenetv3.â€ Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019.
>
> [è®ºæ–‡åœ°å€](https://arxiv.org/abs/1905.02244)
>
> [è®ºæ–‡ä»£ç ](https://github.com/xiaolai-sqlai/mobilenetv3)

### overview

æ·±åº¦å¯åˆ†ç¦»å·ç§¯(depth-wise convolution)

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204091548744.png" alt="image-20220409154846720" width="500" />

1. æ›´æ–°Blockï¼ˆbneckï¼‰

2. ä½¿ç”¨NASæœç´¢å‚æ•°
3. é‡æ–°è®¾è®¡è€—æ—¶å±‚ç»“æ„

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204091549079.png" alt="image-20220409154938056" width="500" />

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204091550226.png" alt="image-20220409155041189" width="500" />



#### v3ç›¸æ¯”v2

- æ›´æ–°Block

1. åŠ å…¥SEæ¨¡å—

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204100052835.png" alt="SE" style="zoom:50%;" />

2. æ›´æ–°æ¿€æ´»å‡½æ•°

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204091556077.png" alt="image-20220409155605016" width="500" />

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204091557420.png" alt="image-20220409155718393" width="500" />

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204170011394.png" alt="image-20220417001114306" style="zoom:50%;" />

1. å‡å°‘ä¸€ä¸ªå·ç§¯å±‚çš„å·ç§¯æ ¸ä¸ªæ•°ï¼ˆ32->16ï¼‰

2. ç²¾ç®€Last stage

![image-20220417001258583](https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204170012613.png)



é‡æ–°è®¾è®¡æ¿€æ´»å‡½æ•°

![image-20220417001420419](https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204170014451.png)

![image-20220417001554740](https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204170015780.png)









### å®éªŒç»“æœ

- exp18
- cfg: yolov5-mobilenetv3-small.yaml
- Model size: 2.0M

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/image-20220407124323895.png" alt="image-20220407124323895"  width="800" />



## Ghostnet

> Han, Kai, et al. â€œGhostnet: More features from cheap operations.â€ Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020.
>
> [è®ºæ–‡åœ°å€](https://arxiv.org/abs/1911.11907)
>
> [è®ºæ–‡ä»£ç ](https://github.com/huawei-noah/CV-Backbones/tree/master/ghostnet_pytorch)





### å®éªŒç»“æœ

#### test1: v6.0

- cfg: yolov5n-ghost.yaml

- exp19
- Model size: 2.4M

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/image-20220407161248022.png" alt="image-20220407161248022" width="800" />

#### test2: v6.1

- cfg: yolov5n-ghost-v61.yaml

- exp20

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/image-20220407195212431.png" alt="image-20220407195212431" width="800" />

#### ç½‘ç»œå¯¹æ¯”

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/image-20220407144724940.png" alt="image-20220407144724940" width="1000" />



##### focus->conv

link: https://github.com/ultralytics/yolov5/issues/4825#issue-998038464

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204100049016.png" alt="Focus" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204100049490.png" alt="Conv" style="zoom:50%;" />



## EfficientNetV2

>[è®ºæ–‡](https://arxiv.org/abs/2104.00298)





# ç½‘ç»œä¼˜åŒ–

## Focusæ¢conv

[Is the Focus layer equivalent to a simple Conv layer? Â· Issue #4825 Â· ultralytics/yolov5 (github.com)](https://github.com/ultralytics/yolov5/issues/4825)

```python
YOLOv5 ğŸš€ 2022-3-15 torch 1.11.0+cu102 CUDA:0 (Tesla V100-PCIE-32GB, 32510.5MB)

      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output
        7040       23.07         2.259         8.273         19.77       (16, 3, 640, 640)      (16, 64, 320, 320)
        7040       23.07         1.860         28.66         38.16       (16, 3, 640, 640)      (16, 64, 320, 320)
        7040       23.07         1.919         8.144         19.86       (16, 3, 640, 640)      (16, 64, 320, 320)
        7040       23.07         1.860         27.21         39.12       (16, 3, 640, 640)      (16, 64, 320, 320)

Process finished with exit code 0
```

![image-20220419205619926](https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204192056965.png)



## sppæ¢sppf

![image-20220419205726284](https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204192057344.png)

## ACONæ¿€æ´»å‡½æ•°

> Ma, Ningning, et al. â€œActivate or not: Learning customized activation.â€ Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.
>
> [è®ºæ–‡åœ°å€](https://arxiv.org/abs/2009.04759)
>
> [è®ºæ–‡ä»£ç ](https://github.com/nmaac/acon/blob/main/acon.py)





## æ³¨æ„åŠ›æœºåˆ¶

### CBAM

> Woo, Sanghyun, et al. â€œCbam: Convolutional block attention module.â€ *Proceedings of the European conference on computer vision (ECCV)*. 2018.
>
> [è®ºæ–‡åœ°å€](https://arxiv.org/abs/1807.06521)

#### overview

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204091659101.png" alt="img" style="zoom:50%;" />

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204091700478.png" alt="img" style="zoom:50%;" />



```python
# ---------------------------- CBAM start ---------------------------------
class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        self.f1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)
        self.relu = nn.ReLU()
        self.f2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)
        self.sigmoid = nn.Sigmoid()
    def forward(self, x):
        avg_out = self.f2(self.relu(self.f1(self.avg_pool(x))))
        max_out = self.f2(self.relu(self.f1(self.max_pool(x))))
        out = self.sigmoid(avg_out + max_out)
        return out
class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()
        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'
        padding = 3 if kernel_size == 7 else 1
        # (ç‰¹å¾å›¾çš„å¤§å°-ç®—å­çš„size+2*padding)/æ­¥é•¿+1
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)
        self.sigmoid = nn.Sigmoid()
    def forward(self, x):
        # 1*h*w
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        x = torch.cat([avg_out, max_out], dim=1)
        #2*h*w
        x = self.conv(x)
        #1*h*w
        return self.sigmoid(x)
class CBAM(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(self, c1, c2, ratio=16, kernel_size=7):  # ch_in, ch_out, number, shortcut, groups, expansion
        super(CBAM, self).__init__()
        self.channel_attention = ChannelAttention(c1, ratio)
        self.spatial_attention = SpatialAttention(kernel_size)
    def forward(self, x):
        out = self.channel_attention(x) * x
        # c*h*w
        # c*h*w * 1*h*w
        out = self.spatial_attention(out) * out
        return out

```



#### å®éªŒç»“æœ

- exp21
- cfg: yolov5-cbam.yaml

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/image-20220407232545101.png" alt="image-20220407232545101" width="800" />



### CAï¼ˆä½ç½®æ³¨æ„åŠ›ï¼‰

> Hou, Qibin, Daquan Zhou, and Jiashi Feng. â€œCoordinate attention for efficient mobile network design.â€ Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.
>
> [è®ºæ–‡åœ°å€](https://arxiv.org/abs/2103.02907)
>
> [è®ºæ–‡ä»£ç ](https://github.com/Andrew-Qibin/CoordAttention)

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204100047262.png" alt="CA" style="zoom:50%;" />

#### å®éªŒç»“æœ

- exp22
- yolov5-ca.yaml

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/image-20220408115306886.png" alt="image-20220408115306886" width="800" />





## SEï¼ˆæŒ¤å‹-æ¿€åŠ±æ³¨æ„åŠ›ï¼‰

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202205031837551.png" alt="image-20220503183736450" style="zoom: 33%;" />

```python
class SE(nn.Module):
    def __init__(self, c1, c2, ratio=16):
        super(SE, self).__init__()
        #c*1*1 c:channel number
        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.l1 = nn.Linear(c1, c1 // ratio, bias=False)
        self.relu = nn.ReLU(inplace=True)
        self.l2 = nn.Linear(c1 // ratio, c1, bias=False)
        self.sig = nn.Sigmoid()
    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avgpool(x).view(b, c)
        y = self.l1(y)
        y = self.relu(y)
        y = self.l2(y)
        y = self.sig(y)
        y = y.view(b, c, 1, 1)
        return x * y.expand_as(x)
```





## BiFPNç‰¹å¾èåˆ

>[Cite]Tan, Mingxing, Ruoming Pang, and Quoc V. Le. â€œEfficientdet: Scalable and efficient object detection.â€ Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.
>
>[è®ºæ–‡åœ°å€](https://arxiv.org/abs/1911.09070)
>
>[è®ºæ–‡ä»£ç ](https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch)





### å®éªŒç»“æœ

- exp23
- cfg: yolov5-bifpn.yaml

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/image-20220408151444731.png" alt="image-20220408151444731" width="800" />





## PP-LCNet-1x



## Transfomer

> [è®ºæ–‡åœ°å€](https://arxiv.org/abs/2010.11929)
>
> [è®ºæ–‡ä»£ç ]()

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204100049079.png" alt="Transformer" style="zoom:50%;" />







- **exp26**
- cfgï¼šyolov5n-transformer.yaml

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204091238744.png" alt="image-20220409123824716" width="800" />



<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204091438730.png" alt="image-20220409143834670" width="800" />





## swinTransformer

>[è®ºæ–‡è¿æ¥]
>
>[ä»£ç è¿æ¥]



## YOLOv5+Ghostconv+BiFPN+CA



### å®éªŒç»“æœ

- exp24
- cfg: yolov5-Ghostconv-BiFPN-CA

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/image-20220408185802294.png" alt="image-20220408185802294" width="800" />







# Results

| train/exp | Model                      | size     (pixels) | mAPval     0.5:0.95 | mAPval     0.5 | FLOPs-train | params(M)   | FLOPs     @640 (B) | val/exp | Speed     V100 b32     (ms) | detect-inference-1  (ms) | Speed     jetson nano     (ms) |
| --------- | -------------------------- | ----------------- | ------------------- | -------------- | ----------- | ----------- | ------------------ | ------- | --------------------------- | ------------------------ | ------------------------------ |
| 25        | yolov5n                    | 640               | 0.607               | 0.937          | 3.9         | 1.76        | 4.5                | 1       | 1.4                         | 9.4                      |                                |
| 17        | yolov5n-shufflenetv2       | 640               | 0.513               | 0.865          | 0.5         | 0.22        | 0.5                | 2       | 0.5                         | 10.6                     |                                |
| 18        | yolov5n-mobilenetv3        | 640               | 0.564               | 0.91           | 1.2         | 0.79        | 1.2                | 3       | 1.1                         | 14.5                     |                                |
| 19        | yolov5n-ghost              | 640               | 0.599               | 0.934          | 2.3         | 0.94        | 2.3                | 4       | 1..0                        | 13.4                     |                                |
| 20        | yolov5n-ghost-v61          | 640               | 0.592               | 0.933          | 2.3         | 0.94(0.939) | 2.3                | 5       | 1.4                         | 13.9                     |                                |
| 21        | yolov5n-cbam               | 640               | 0.61                | 0.939          | 3.8         | 1.69        | 4.1                | 6       | 1.9                         | 15.3                     |                                |
| 22        | yolov5n-ca                 | 640               | 0.618               | 0.946          |             | 1.77        |                    | 7       | 1.6                         | 10.9                     |                                |
| 23        | yolov5n-bifpn              | 640               | 0.612               | 0.939          | 4.2         | 1.78        | 4.2                | 8       | 1.4                         | 0.9                      |                                |
| 24        | yolov5n-Ghostconv-BiFPN-CA | 640               | 0.606               | 0.94           |             | 1.49        |                    | 9       | 1.5                         | 10.2                     |                                |
|           |                            |                   |                     |                |             |             |                    |         |                             |                          |                                |



## å¯¹æ¯”ï¼š

yolov5nè¯¯åˆ¤ï¼š

005308ã€005316ã€005322ã€005354ã€005395

ç‰¹æ®Šæƒ…å†µæ— æ³•åˆ¤æ–­ï¼š005381(è¹²ä¸‹åªæœ‰å¤´ç›”)

å°ç›®æ ‡æ¼æ£€ï¼š005351

å¤æ‚æƒ…å†µï¼ˆåƒç´ è¿‡ä½oræƒ…å†µå¤æ‚ï¼‰ï¼š005384



| <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/005308_jpg.rf.4403a2f5f05f7715de6bdd234a24f8e3.jpg" alt="005308_jpg.rf.4403a2f5f05f7715de6bdd234a24f8e3" style="zoom:50%;" /> | <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204090131552.jpg" alt="005308_jpg.rf.4403a2f5f05f7715de6bdd234a24f8e3" style="zoom:50%;" /> |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/005316_jpg.rf.45c8dd29cadc2f60f46a4ce0a4f9b9b9.jpg" alt="005316_jpg.rf.45c8dd29cadc2f60f46a4ce0a4f9b9b9" style="zoom:50%;" /> | <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204090143364.jpg" alt="005316_jpg.rf.45c8dd29cadc2f60f46a4ce0a4f9b9b9" style="zoom:50%;" /> |
| <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/005322_jpg.rf.38c87c9a9999606bd5936d6ddb6915b2.jpg" alt="005322_jpg.rf.38c87c9a9999606bd5936d6ddb6915b2" style="zoom:50%;" /> | <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204090132797.jpg" alt="005322_jpg.rf.38c87c9a9999606bd5936d6ddb6915b2" style="zoom:50%;" /> |
| <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/005354_jpg.rf.66ac8412f01e08a6146d5bc63bbb158c.jpg" alt="005354_jpg.rf.66ac8412f01e08a6146d5bc63bbb158c" style="zoom:50%;" /> | <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204090133114.jpg" alt="005354_jpg.rf.66ac8412f01e08a6146d5bc63bbb158c" style="zoom:50%;" /> |
| <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/005395_jpg.rf.a38830389c0d26e139ba81b2e1a813a3.jpg" alt="005395_jpg.rf.a38830389c0d26e139ba81b2e1a813a3" style="zoom:50%;" /> | <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204090136681.jpg" alt="005395_jpg.rf.a38830389c0d26e139ba81b2e1a813a3" style="zoom:50%;" /> |
|                                                              |                                                              |



| <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204090137571.jpg" alt="005381_jpg.rf.be7a0d23f9a13d1e0321014db768002f" style="zoom:50%;" /> | <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204090137290.jpg" alt="005381_jpg.rf.be7a0d23f9a13d1e0321014db768002f" style="zoom:50%;" /> |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
|                                                              |                                                              |

| <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204090138086.jpg" alt="005351_jpg.rf.ed2d454b2e059fc13f901bcc62947bfa" style="zoom:50%;" /> | :x:  |
| :----------------------------------------------------------: | :--: |
| <img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204090139807.jpg" alt="005384_jpg.rf.34ab47f3859c29a33df2780579333dc1" style="zoom:50%;" /> | :x:  |
|                                                              |      |





# å…¶ä»–æµ‹è¯•

## SPP-SPPF

`SPP`:å°†è¾“å…¥å¹¶è¡Œé€šè¿‡å¤šä¸ªä¸åŒå¤§å°çš„`MaxPool`ï¼Œç„¶ååšè¿›ä¸€æ­¥èåˆï¼Œèƒ½åœ¨ä¸€å®šç¨‹åº¦ä¸Šè§£å†³ç›®æ ‡å¤šå°ºåº¦é—®é¢˜ã€‚

è€Œ`SPPF`ç»“æ„æ˜¯å°†è¾“å…¥ä¸²è¡Œé€šè¿‡å¤šä¸ª`5x5`å¤§å°çš„`MaxPool`å±‚ï¼Œè¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ä¸²è¡Œä¸¤ä¸ª`5x5`å¤§å°çš„`MaxPool`å±‚æ˜¯å’Œä¸€ä¸ª`9x9`å¤§å°çš„`MaxPool`å±‚è®¡ç®—ç»“æœæ˜¯ä¸€æ ·çš„ï¼Œä¸²è¡Œä¸‰ä¸ª`5x5`å¤§å°çš„`MaxPool`å±‚æ˜¯å’Œä¸€ä¸ª`13x13`å¤§å°çš„`MaxPool`å±‚è®¡ç®—ç»“æœæ˜¯ä¸€æ ·çš„ã€‚



<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204100048248.png" alt="SPP" style="zoom:50%;" />

**SPP vs SPPF**

<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204091152646.png" alt="image-20220409115240561" style="zoom:50%;" />





## yolov5n6

- **exp27**
- cfgï¼šyolov5n6

![image-20220409161148223](https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204091611250.png)





## tph-yolov5æµ‹è¯•

>[è®ºæ–‡åœ°å€]()
>
>[è®ºæ–‡ä»£ç ]()





## YOLOX

> [è®ºæ–‡åœ°å€]([[2107.08430\] YOLOX: Exceeding YOLO Series in 2021 (arxiv.org)](https://arxiv.org/abs/2107.08430))
>
> [è®ºæ–‡ä»£ç ]([Megvii-BaseDetection/YOLOX: YOLOX is a high-performance anchor-free YOLO, exceeding yolov3~v5 with MegEngine, ONNX, TensorRT, ncnn, and OpenVINO supported. Documentation: https://yolox.readthedocs.io/ (github.com)](https://github.com/Megvii-BaseDetection/YOLOX))



## æ•°æ®å¢å¼º



<img src="https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204171147435.jpg" alt="preview" style="zoom:50%;" />

æ€»å…±åˆ†æˆä¸Šè¿° 4 ä¸ªæ­¥éª¤ï¼Œæ•´ä½“æµç¨‹å¦‚ä¸‹å›¾æ‰€ç¤º(å‰ä¸¤æ­¥æ˜¯é©¬èµ›å…‹å¢å¼ºï¼Œç¬¬ä¸‰æ­¥æ˜¯å‡ ä½•å˜æ¢å¢å¼ºï¼Œç¬¬ 4 æ­¥æ˜¯ MixUp å¢å¼º

\1) é©¬èµ›å…‹å¢å¼º

1. éšæœºå‡º 4 å¼ å›¾ç‰‡åœ¨å¾…è¾“å‡ºå›¾ç‰‡ä¸­äº¤æ¥çš„ä¸­å¿ƒç‚¹åæ ‡
2. éšæœºå‡ºå¦å¤– 3 å¼ å›¾ç‰‡çš„ç´¢å¼•ä»¥åŠè¯»å–å¯¹åº”çš„æ ‡æ³¨
3. å¯¹æ¯å¼ å›¾ç‰‡é‡‡ç”¨ä¿æŒå®½é«˜æ¯”çš„ resize æ“ä½œç¼©æ”¾åˆ°æŒ‡å®šå¤§å°
4. æŒ‰ç…§ä¸Šä¸‹å·¦å³è§„åˆ™ï¼Œè®¡ç®—æ¯å¼ å›¾ç‰‡åœ¨å¾…è¾“å‡ºå›¾ç‰‡ä¸­åº”è¯¥æ”¾ç½®çš„ä½ç½®ï¼Œå› ä¸ºå›¾ç‰‡å¯èƒ½å‡ºç•Œæ•…è¿˜éœ€è¦è®¡ç®—è£å‰ªåæ ‡
5. åˆ©ç”¨è£å‰ªåæ ‡å°†ç¼©æ”¾åçš„å›¾ç‰‡è£å‰ªï¼Œç„¶åè´´åˆ°å‰é¢è®¡ç®—å‡ºçš„ä½ç½®ï¼Œå…¶ä½™ä½ç½®å…¨éƒ¨è¡¥ 114 åƒç´ å€¼
6. å¯¹æ¯å¼ å›¾ç‰‡çš„æ ‡æ³¨ä¹Ÿè¿›è¡Œç›¸åº”å¤„ç†
7. ç”±äºæ‹¼æ¥äº† 4 å¼ å›¾ï¼Œæ‰€ä»¥è¾“å‡ºå›¾ç‰‡å¤§å°ä¼šæ‰©å¤§ 4 å€

\2) å‡ ä½•å˜æ¢å¢å¼º

random_perspective åŒ…æ‹¬å¹³ç§»ã€æ—‹è½¬ã€ç¼©æ”¾ã€é”™åˆ‡ç­‰å¢å¼ºï¼Œå¹¶ä¸”ä¼šå°†è¾“å…¥å›¾ç‰‡è¿˜åŸä¸º (640, 640)ï¼ŒåŒæ—¶å¯¹å¢å¼ºåçš„æ ‡æ³¨è¿›è¡Œå¤„ç†ï¼Œè¿‡æ»¤è§„åˆ™æ˜¯

1. å¢å¼ºåçš„ gt bbox å®½é«˜è¦å¤§äº wh_thr
2. å¢å¼ºåçš„ gt bbox é¢ç§¯å’Œå¢å¼ºå‰çš„ gt bbox é¢ç§¯è¦å¤§äº ar_thrï¼Œé˜²æ­¢å¢å¼ºå¤ªä¸¥é‡
3. æœ€å¤§å®½é«˜æ¯”è¦å°äº area_thrï¼Œé˜²æ­¢å®½é«˜æ¯”æ”¹å˜å¤ªå¤š

\3) MixUp

Mixup å®ç°æ–¹æ³•æœ‰å¤šç§ï¼Œå¸¸è§çš„åšæ³•æ˜¯ï¼šè¦ä¹ˆ label ç›´æ¥æ‹¼æ¥èµ·æ¥ï¼Œè¦ä¹ˆ label ä¹Ÿé‡‡ç”¨ alpha æ··åˆï¼Œä½œè€…çš„åšæ³•éå¸¸ç®€å•ï¼Œå¯¹ label ç›´æ¥æ‹¼æ¥å³å¯ï¼Œè€Œå›¾ç‰‡ä¹Ÿæ˜¯é‡‡ç”¨å›ºå®šçš„ 0.5:0.5 æ··åˆæ–¹æ³•ã€‚

å…¶å¤„ç†æµç¨‹æ˜¯ï¼š

1. éšæœºå‡ºä¸€å¼ å›¾ç‰‡ï¼Œå¿…é¡»è¦ä¿è¯è¯¥å›¾ç‰‡ä¸æ˜¯ç©ºæ ‡æ³¨
2. å¯¹éšæœºå‡ºçš„å›¾ç‰‡é‡‡ç”¨ä¿æŒå®½é«˜æ¯”çš„ resize æ“ä½œç¼©æ”¾åˆ°æŒ‡å®šå¤§å°
3. ç„¶åå·¦ä¸Š padding æˆæŒ‡å®šå¤§å°ï¼Œpadding å€¼ä¹Ÿæ˜¯ 114
4. å¯¹ padding åçš„å›¾ç‰‡è¿›è¡ŒéšæœºæŠ–åŠ¨å¢å¼º
5. éšæœºé‡‡ç”¨ flip å¢å¼º
6. å¦‚æœå¤„ç†åçš„å›¾ç‰‡æ¯”åŸå›¾å¤§ï¼Œåˆ™è¿˜éœ€è¦è¿›è¡Œéšæœºè£å‰ªå¢å¼º
7. å¯¹æ ‡ç­¾è¿›è¡Œå¯¹åº”å¤„ç†ï¼Œå¹¶ä¸”é‡‡ç”¨å’Œé©¬èµ›å…‹å¢å¼ºä¸€æ ·çš„è¿‡æ»¤è§„åˆ™
8. å¦‚æœè¿‡æ»¤åè¿˜å­˜åœ¨ gt bboxï¼Œåˆ™é‡‡ç”¨ 0.5:0.5 çš„æ¯”ä¾‹æ··åˆåŸå›¾å’Œå¤„ç†åçš„å›¾ç‰‡ï¼Œæ ‡ç­¾åˆ™ç›´æ¥æ‹¼æ¥å³å¯

\4) å›¾ç‰‡åå¤„ç†

å›¾ç‰‡åå¤„ç†æ“ä½œä¹ŸåŒ…æ‹¬ä¼—å¤šæ•°æ®å¢å¼ºæ“ä½œï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

1. éšæœº ColorJitï¼ŒåŒ…æ‹¬ä¼—å¤šé¢œè‰²ç›¸å…³å¢å¼º
2. éšæœºç¿»è½¬å¢å¼º
3. å¯¹éšæœºåçš„å›¾ç‰‡é‡‡ç”¨ä¿æŒå®½é«˜æ¯”çš„ resize æ“ä½œç¼©æ”¾åˆ°æŒ‡å®šå¤§å°
4. å¯¹äºå®½é«˜å°äº 8 åƒç´ çš„ gt bbox ç›´æ¥åˆ æ‰ï¼Œå› ä¸ºç½‘ç»œè¾“å‡ºçš„æœ€å° stride æ˜¯ 8
5. Padding æˆæ­£æ–¹å½¢å›¾ç‰‡è¾“å‡º

 

# è°ƒå‚

## lrf(æœ€ç»ˆ OneCycleLR å­¦ä¹ ç‡)

[CosineAnnealingLRå’ŒOneCycleLRçš„åŸç†ä¸ä½¿ç”¨ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/350712244)



### lrf: 0.01

- exp28
- yolov5n-Helmet.yaml
- batchï¼š128
- data/hyps/hyp.scratch-low.yaml
- lrf: 0.01  # final OneCycleLR learning rate (lr0 * lrf)

**[result](https://wandb.ai/yin-qiyu/helmet/runs/10g70rjo?workspace=user-yin-qiyu)**





### lrf: 0.1

- exp29

- yolov5n-Helmet.yaml
- batchï¼š128
- data/hyps/hyp.scratch-low.yaml
- lrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)

**[result](https://wandb.ai/yin-qiyu/helmet/runs/j01nvbgy?workspace=user-yin-qiyu)**





# è¶…å‚

ç½‘ç»œæœç´¢ï¼Œéšæœºæœç´¢ï¼Œè´å¶æ–¯æœç´¢

ssh -p 17025 root@region-11.autodl.com 

ssh -p 24454 root@region-11.autodl.com 

wandb login --relogin

![image-20220410135410006](https://raw.githubusercontent.com/yin-qiyu/picbed/master/img/202204101354035.png)





## é—ä¼ ç®—æ³•

**exp30**

exp31





# TO DO

+ [x] backbone: ShuffleNetV2
+ [x] backbone: Mobilenetv3
+ [x] backbone: Ghostnet:star:
+ [x] backboneï¼šCBAN
+ [x] backboneï¼šCA
+ [x] head:BiFPN
+ [x] YOLOv5+Ghostconv+BiFPN+CAâ­ï¸
+ [x] backbone: c3tr
+ [ ] Backbone:c3str
+ [ ] Prune: FSP
+ [ ] contrastğŸš€
+ [ ] tph-yolov5
+ [ ] yolox
+ [ ] hyp
  + [ ] lrf



# å¾…è§£å†³

## é¡¹ç›®è½åœ°

- [ ] å°ç›®æ ‡æ•°æ®é›†

- [ ] 



- ç®€å•æ•°æ®é›†ï¼š
  - ç‰¹å¾æ˜æ˜¾
  - ç±»åˆ«å°‘
  - ç›®æ ‡å¤§
